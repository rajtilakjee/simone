{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Simone","text":"<p>A Python script to repurpose your YouTube videos as blog posts and context-aware screenshots.</p>"},{"location":"#about","title":"About","text":"<p>Fun LLM challenge that I'm thinking about: take my 2h13m tokenizer video and translate the video into the format of a book chapter (or a blog post) on tokenization. Something like:</p> <ol> <li>Whisper the video</li> <li>Chop up into segments of aligned images and text</li> <li>Prompt engineer an LLM to translate piece by piece</li> <li>Export as a page, with links citing parts of original video</li> </ol> <p>More generally, a workflow like this could be applied to any input video and auto-generate \"companion guides\" for various tutorials in a more readable, skimmable, searchable format. Feels tractable but non-trivial.</p> <p>-- Andrej Karpathy, X/Twitter, Feb 2024</p> <p>This is what inspired to start this project.</p>"},{"location":"#how-does-it-work","title":"How does it Work","text":"<p>Got 2 minutes? Check out a video overview of our product:</p> <p></p>"},{"location":"#use-cases","title":"Use Cases","text":"<ul> <li>YouTube Video Conversion: Extract video content from YouTube URLs.</li> <li>Context-Aware Screenshots: Automatically capture relevant screenshots based on video content.</li> <li>Blog Post Generation: Create informative blog posts with embedded screenshots.</li> <li>SEO Optimization: Enhance SEO by repurposing video content into written format.</li> <li>Command-Line Interface: Easy-to-use CLI for seamless conversion and post-generation.</li> </ul>"},{"location":"code-overview/blogger/","title":"Blogger Class","text":""},{"location":"code-overview/blogger/#description","title":"Description","text":"<p>The <code>Blogger</code> class provides functionality for generating blog posts using the OpenAI API. It takes a transcription file as input, sends it to the OpenAI API, and saves the generated blog post to an output file.</p>"},{"location":"code-overview/blogger/#class-definition","title":"Class Definition","text":"<pre><code>class Blogger:\n    def __init__(self, api_key, transcription_filename, output_filename):\n        \"\"\"\n        Initialize the Blogger instance.\n\n        Parameters:\n            api_key : str\n                Your OpenAI API key for authentication.\n            transcription_filename : str\n                The filename of the transcription file containing content for the blog post.\n            output_filename : str\n                The filename for saving the generated blog post.\n        \"\"\"\n        pass\n\n    def generate_blogpost(self):\n        \"\"\"\n        Generate a blog post using the OpenAI API and save it to the output file.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"code-overview/blogger/#methods","title":"Methods","text":"<p><code>__init__(api_key, transcription_filename, output_filename)</code> - Initializes a Blogger instance with the provided API key, transcription filename, and output filename.</p> <p><code>generate_blogpost()</code> - Generates a blog post using the content from the transcription file and saves it to the output file.</p>"},{"location":"code-overview/blogger/#example-usage","title":"Example Usage","text":"<pre><code># Initialize Blogger instance\nblogger = Blogger(api_key=\"YOUR_API_KEY\", transcription_filename=\"transcription.txt\", output_filename=\"output.txt\")\n\n# Generate and save blog post\nblogger.generate_blogpost()\n</code></pre>"},{"location":"code-overview/blogger/#usage-notes","title":"Usage Notes","text":"<ul> <li>Ensure you have a valid OpenAI API key (api_key) before using the Blogger class.</li> <li>Provide the correct filenames for the transcription file (transcription_filename) and the output file (output_filename).</li> <li>The generate_blogpost() method sends the transcription content to the OpenAI API and saves the generated blog post to the specified output file.</li> </ul>"},{"location":"code-overview/blogger/#dependencies","title":"Dependencies","text":"<ul> <li>json: Used for JSON handling.</li> <li>requests: Used for making HTTP requests to the OpenAI API.</li> </ul>"},{"location":"code-overview/blogger/#related-links","title":"Related Links","text":"<ul> <li>OpenAI API Documentation</li> <li>Requests Library Documentation</li> </ul>"},{"location":"code-overview/downloader/","title":"Downloader Class","text":""},{"location":"code-overview/downloader/#description","title":"Description","text":"<p>The <code>Downloader</code> class provides methods for downloading audio and video files from YouTube using the pytube library.</p>"},{"location":"code-overview/downloader/#class-definition","title":"Class Definition","text":"<pre><code>from __future__ import annotations\nfrom pytube import YouTube\n\nclass Downloader:\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize the Downloader instance.\n\n        Parameters:\n            url : str\n                The YouTube video URL to download.\n        \"\"\"\n        pass\n\n    def audio(self):\n        \"\"\"\n        Download the audio-only version of the YouTube video.\n        \"\"\"\n        pass\n\n    def video(self):\n        \"\"\"\n        Download the highest resolution video of the YouTube video.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"code-overview/downloader/#methods","title":"Methods","text":"<p><code>__init__(url)</code> - Initializes a Downloader instance with the provided YouTube video URL (url).</p> <p><code>audio()</code> - Downloads the audio-only version of the YouTube video.</p> <p><code>video()</code> - Downloads the highest resolution video of the YouTube video.</p>"},{"location":"code-overview/downloader/#example-usage","title":"Example Usage","text":"<pre><code># Initialize Downloader instance\ndownloader = Downloader(url=\"https://www.youtube.com/watch?v=VIDEO_ID\")\n\n# Download audio-only version\ndownloader.audio()\n\n# Download highest resolution video\ndownloader.video()\n</code></pre>"},{"location":"code-overview/downloader/#usage-notes","title":"Usage Notes","text":"<ul> <li>Ensure you have the pytube library installed (pip install pytube).</li> <li>Provide a valid YouTube video URL when initializing the Downloader instance.</li> <li>The audio() method downloads the audio-only version of the video and saves it as \"audio.mp4\" in the current directory.</li> <li>The video() method downloads the highest resolution video and saves it as \"video.mp4\" in the current directory.</li> </ul>"},{"location":"code-overview/downloader/#dependencies","title":"Dependencies","text":"<ul> <li>pytube: Used for downloading YouTube videos.</li> </ul>"},{"location":"code-overview/downloader/#related-links","title":"Related Links","text":"<ul> <li>pytube Documentation</li> <li>YouTube API</li> </ul>"},{"location":"code-overview/framer/","title":"Framer Class","text":""},{"location":"code-overview/framer/#description","title":"Description","text":"<p>The <code>Framer</code> class provides functionality for extracting frames from a video file using the OpenCV library.</p>"},{"location":"code-overview/framer/#class-definition","title":"Class Definition","text":"<pre><code>from __future__ import annotations\nimport cv2\n\nclass Framer:\n    def __init__(self, filename: str):\n        \"\"\"\n        Initialize the Framer instance.\n\n        Parameters:\n            filename : str\n                The filename of the video file to extract frames from.\n        \"\"\"\n        pass\n\n    def get_video_frames(self):\n        \"\"\"\n        Extract frames from the video file.\n\n        Returns:\n            list\n                A list of frames extracted from the video.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"code-overview/framer/#methods","title":"Methods","text":"<p><code>__init__(filename)</code> - Initializes a Framer instance with the provided video file filename.</p> <p><code>get_video_frames()</code> - Extracts frames from the video file and returns a list of frames.</p>"},{"location":"code-overview/framer/#example-usage","title":"Example Usage","text":"<pre><code># Initialize Framer instance\nframer = Framer(filename=\"video.mp4\")\n\n# Get video frames\nframes = framer.get_video_frames()\n</code></pre>"},{"location":"code-overview/framer/#usage-notes","title":"Usage Notes","text":"<ul> <li>Ensure you have the OpenCV library installed (pip install opencv-python).</li> <li>Provide the correct video file filename when initializing the Framer instance.</li> <li>The get_video_frames() method extracts frames from the video file and returns them as a list of frames.</li> </ul>"},{"location":"code-overview/framer/#dependencies","title":"Dependencies","text":"<ul> <li>cv2 (OpenCV): Used for working with images and videos.</li> </ul>"},{"location":"code-overview/framer/#related-links","title":"Related Links","text":"<ul> <li>OpenCV Documentation</li> </ul>"},{"location":"code-overview/main/","title":"Point of Entry","text":""},{"location":"code-overview/main/#description","title":"Description","text":"<p>This script automates the process of generating a blog post from a YouTube video by performing the following steps:</p> <ol> <li>Downloads the audio and video from the YouTube video.</li> <li>Transcribes the audio into text.</li> <li>Generates a summary of keywords from the transcription.</li> <li>Creates a blog post using the generated summary.</li> <li>Extracts frames from the video and scores them based on the keywords.</li> <li>Saves the best frames as images.</li> </ol>"},{"location":"code-overview/main/#usage","title":"Usage","text":"<ol> <li>Make sure you have set up the necessary environment variables and installed the required libraries.</li> <li>Run the script and provide the YouTube URL when prompted.</li> </ol>"},{"location":"code-overview/main/#steps","title":"Steps","text":"<ol> <li>Enter YouTube URL: [Provide the YouTube video URL]</li> <li>The script will download the audio and video, transcribe the audio, generate a summary of keywords, create a blog post, extract frames, score them, and save the best frames.</li> </ol>"},{"location":"code-overview/main/#dependencies","title":"Dependencies","text":"<ul> <li>Python libraries:</li> <li><code>requests</code>: Used for making HTTP requests.</li> <li> <p><code>dotenv</code>: Used for loading environment variables from a <code>.env</code> file.</p> </li> <li> <p>Custom utility modules:</p> </li> <li><code>Downloader</code>: Downloads audio and video from YouTube.</li> <li><code>Transcriber</code>: Transcribes audio files into text.</li> <li><code>Summarizer</code>: Generates keyword summaries from text content using an API.</li> <li><code>Blogger</code>: Generates blog posts using keyword summaries.</li> <li><code>Framer</code>: Extracts frames from videos.</li> <li><code>Scorer</code>: Scores frames based on keywords.</li> <li><code>Saver</code>: Saves the best frames as images.</li> </ul>"},{"location":"code-overview/main/#related-links","title":"Related Links","text":"<ul> <li>requests Documentation</li> <li>dotenv Documentation</li> </ul>"},{"location":"code-overview/saver/","title":"Saver Class","text":""},{"location":"code-overview/saver/#description","title":"Description","text":"<p>The <code>Saver</code> class provides functionality for saving the best frames from a list of frames based on their scores using the OpenCV and NumPy libraries.</p>"},{"location":"code-overview/saver/#class-definition","title":"Class Definition","text":"<pre><code>from __future__ import annotations\nimport cv2\nimport numpy as np\n\nclass Saver:\n    def __init__(self, frames: list, scores: list):\n        \"\"\"\n        Initialize the Saver instance.\n\n        Parameters:\n            frames : list\n                A list of frames (images) to be saved.\n            scores : list\n                A list of scores corresponding to the frames.\n        \"\"\"\n        pass\n\n    def save_best_frames(self):\n        \"\"\"\n        Save the best frames based on their scores.\n\n        Notes:\n            Assumes that the frames and scores lists are non-empty and have the same length.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"code-overview/saver/#methods","title":"Methods","text":"<p><code>__init__(frames, scores)</code> - Initializes a Saver instance with the provided lists of frames and scores.</p> <p><code>save_best_frames()</code> - Saves the best frames from the list based on their scores.</p>"},{"location":"code-overview/saver/#example-usage","title":"Example Usage","text":"<pre><code># Assuming 'frames' and 'scores' are defined elsewhere\nframes = [...]  # List of frames\nscores = [...]  # List of scores\n\n# Initialize Saver instance\nsaver = Saver(frames=frames, scores=scores)\n\n# Save the best frames\nsaver.save_best_frames()\n</code></pre>"},{"location":"code-overview/saver/#usage-notes","title":"Usage Notes","text":"<ul> <li>Ensure you have the OpenCV (cv2) and NumPy (np) libraries installed (pip install opencv-python numpy).</li> <li>Provide non-empty lists of frames and scores when initializing the Saver instance.</li> <li>The save_best_frames() method saves the top three frames with the highest scores as JPEG images.</li> </ul>"},{"location":"code-overview/saver/#dependencies","title":"Dependencies","text":"<ul> <li>cv2 (OpenCV): Used for image processing and saving images.</li> <li>numpy: Used for numerical computations and array manipulations.</li> </ul>"},{"location":"code-overview/saver/#related-links","title":"Related Links","text":"<ul> <li>OpenCV Documentation</li> <li>NumPy Documentation</li> </ul>"},{"location":"code-overview/scorer/","title":"Scorer Class","text":""},{"location":"code-overview/scorer/#description","title":"Description","text":"<p>The <code>Scorer</code> class provides functionality for scoring frames based on the presence of keywords using the pytesseract library for OCR (Optical Character Recognition) and OpenCV library for image processing.</p>"},{"location":"code-overview/scorer/#class-definition","title":"Class Definition","text":"<pre><code>from __future__ import annotations\nimport cv2\nimport pytesseract\nfrom pytesseract import Output\n\nclass Scorer:\n    def __init__(self, frames: list, keywords: list):\n        \"\"\"\n        Initialize the Scorer instance.\n\n        Parameters:\n            frames : list\n                A list of frames (images) to be scored.\n            keywords : list\n                A list of keywords to search for in the frames.\n        \"\"\"\n        pass\n\n    def score_frames(self) -&gt; list[int]:\n        \"\"\"\n        Score the frames based on the presence of keywords.\n\n        Returns:\n            list[int]\n                A list of scores corresponding to each frame.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"code-overview/scorer/#methods","title":"Methods","text":"<p><code>__init__(frames, keywords)</code> - Initializes a Scorer instance with the provided lists of frames and keywords.</p> <p><code>score_frames()</code> - Scores the frames based on the presence of keywords and returns a list of scores.</p>"},{"location":"code-overview/scorer/#example-usage","title":"Example Usage","text":"<pre><code># Assuming 'frames' and 'keywords' are defined elsewhere\nframes = [...]  # List of frames\nkeywords = [...]  # List of keywords\n\n# Initialize Scorer instance\nscorer = Scorer(frames=frames, keywords=keywords)\n\n# Score the frames\nscores = scorer.score_frames()\n</code></pre>"},{"location":"code-overview/scorer/#usage-notes","title":"Usage Notes","text":"<ul> <li>Ensure you have the pytesseract and OpenCV (cv2) libraries installed (pip install pytesseract opencv-python).</li> <li>Provide non-empty lists of frames and keywords when initializing the Scorer instance.</li> <li>The score_frames() method uses OCR to extract text from frames and scores each frame based on the presence of keywords.</li> </ul>"},{"location":"code-overview/scorer/#dependencies","title":"Dependencies","text":"<ul> <li>cv2 (OpenCV): Used for image processing.</li> <li>pytesseract: Used for Optical Character Recognition (OCR).</li> </ul>"},{"location":"code-overview/scorer/#related-links","title":"Related Links","text":"<ul> <li>pytesseract Documentation</li> <li>OpenCV Documentation</li> </ul>"},{"location":"code-overview/summarizer/","title":"Summarizer Class","text":""},{"location":"code-overview/summarizer/#description","title":"Description","text":"<p>The <code>Summarizer</code> class provides functionality for generating summaries of text content using the OpenAI API.</p>"},{"location":"code-overview/summarizer/#class-definition","title":"Class Definition","text":"<pre><code>from __future__ import annotations\nimport json\nimport requests\n\nclass Summarizer:\n    def __init__(self, api_key: str, transcription_filename: str):\n        \"\"\"\n        Initialize the Summarizer instance.\n\n        Parameters:\n            api_key : str\n                Your OpenAI API key for authentication.\n            transcription_filename : str\n                The filename of the transcription file containing content for summarization.\n        \"\"\"\n        pass\n\n    def generate_summary(self) -&gt; str:\n        \"\"\"\n        Generate a summary of the text content.\n\n        Returns:\n            str\n                The generated summary.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"code-overview/summarizer/#methods","title":"Methods","text":"<p><code>__init__(api_key, transcription_filename)</code> - Initializes a Summarizer instance with the provided OpenAI API key and transcription filename.</p> <p><code>generate_summary()</code> - Generates a summary of the text content using the OpenAI API and returns it.</p>"},{"location":"code-overview/summarizer/#example-usage","title":"Example Usage","text":"<pre><code># Initialize Summarizer instance\nsummarizer = Summarizer(api_key=\"YOUR_API_KEY\", transcription_filename=\"transcription.txt\")\n\n# Generate summary\nsummary = summarizer.generate_summary()\n</code></pre>"},{"location":"code-overview/summarizer/#usage-notes","title":"Usage Notes","text":"<ul> <li>Ensure you have a valid OpenAI API key (api_key) before using the Summarizer class.</li> <li>Provide the correct filename for the transcription file (transcription_filename).</li> <li>The generate_summary() method sends the text content to the OpenAI API and retrieves a summary.</li> </ul>"},{"location":"code-overview/summarizer/#dependencies","title":"Dependencies","text":"<ul> <li>json: Used for JSON handling.</li> <li>requests: Used for making HTTP requests to the OpenAI API.</li> </ul>"},{"location":"code-overview/summarizer/#related-links","title":"Related Links","text":"<ul> <li>OpenAI API Documentation</li> <li>Requests Library Documentation</li> </ul>"},{"location":"code-overview/transcriber/","title":"Transcriber Class","text":""},{"location":"code-overview/transcriber/#description","title":"Description","text":"<p>The <code>Transcriber</code> class provides functionality for transcribing audio files using the whisper library.</p>"},{"location":"code-overview/transcriber/#class-definition","title":"Class Definition","text":"<pre><code>from __future__ import annotations\nimport whisper\nfrom whisper.utils import get_writer\n\nclass Transcriber:\n    def __init__(self, filename: str):\n        \"\"\"\n        Initialize the Transcriber instance.\n\n        Parameters:\n            filename : str\n                The filename of the audio file to transcribe.\n        \"\"\"\n        pass\n\n    def transcribe(self):\n        \"\"\"\n        Transcribe the audio file and save the transcription in a text file (UTF-8) and an SRT file.\n\n        Notes:\n            The transcription text file will be named \"transcription.txt\" in the current directory.\n            The SRT file will be created in the specified output directory (default: \"./\").\n        \"\"\"\n        pass\n</code></pre>"},{"location":"code-overview/transcriber/#methods","title":"Methods","text":"<p><code>__init__(filename)</code> - Initializes a Transcriber instance with the provided audio file filename.</p> <p><code>transcribe()</code> - Transcribes the audio file and saves the transcription in a text file (UTF-8) and an SRT file.</p>"},{"location":"code-overview/transcriber/#example-usage","title":"Example Usage","text":"<pre><code># Initialize Transcriber instance\ntranscriber = Transcriber(filename=\"audio.wav\")\n\n# Transcribe the audio file\ntranscriber.transcribe()\n</code></pre>"},{"location":"code-overview/transcriber/#usage-notes","title":"Usage Notes","text":"<ul> <li>Ensure you have the whisper library installed (pip install whisper).</li> <li>Provide the correct audio file filename when initializing the Transcriber instance.</li> <li>The transcribe() method transcribes the audio file using the whisper library and saves the transcription in a text file named \"transcription.txt\" and an SRT file.</li> </ul>"},{"location":"code-overview/transcriber/#dependencies","title":"Dependencies","text":"<ul> <li>whisper: Used for audio transcription.</li> </ul>"},{"location":"code-overview/transcriber/#related-links","title":"Related Links","text":"<ul> <li>whisper Documentation</li> </ul>"},{"location":"getting-started/dependencies/","title":"Dependencies","text":"<p>Simone requires the following dependencies to be installed on your system:</p> <ul> <li>FFmpeg: Used for video processing and screenshot extraction. Install FFmpeg from here</li> <li>Tesseract OCR Engine: Used for text recognition in screenshots. Install Tesseract OCR Engine from here</li> <li>OpenRouter: Used for generating the blog post and keywords. You need to obtain an API Key for Gemma 7B from OpenRouter for free. Find out more about OpenRouter from here</li> </ul>"},{"location":"getting-started/dependencies/#tech-stack","title":"Tech Stack","text":"<p>This project leverages the following technologies and libraries:</p> <ul> <li>Python: The core language used for scripting and automation.</li> <li>FFmpeg: Used for video processing and screenshot extraction.</li> <li>Tesseract OCR Engine: Used for text recognition in screenshots.</li> <li>Gemma 7B: Used for generating blog posts and related keywords.</li> <li>OpenRouter: For using the Gemma 7B free API.</li> </ul> <p>The project also uses other Python libraries for various functionalities. Refer to the <code>requirements.txt</code> file for a full list of dependencies.</p>"},{"location":"getting-started/installation/","title":"Installation and Usage","text":"<p>These are the details you need to follow in order to make Simone work on your local system. Before installing Simone, you need to install the dependencies.</p>"},{"location":"getting-started/installation/#install-ffmpeg","title":"Install FFMPEG:","text":"<ol> <li>Download it from the following link: https://ffmpeg.org/download.html</li> <li>Follow the instructions on the screen to install it.</li> </ol>"},{"location":"getting-started/installation/#install-tesseract-ocr","title":"Install Tesseract OCR:","text":"<ol> <li>Visit the following page for detailed instructions on how to install Tesseract OCR in your system: https://tesseract-ocr.github.io/tessdoc/Installation.html</li> </ol> <p>[!IMPORTANT] Remember to find out the path where Tesseract OCR was installed in your system. You'll need this during execution of the program.</p>"},{"location":"getting-started/installation/#gemma-7b-api-key","title":"Gemma 7B API Key:","text":"<ol> <li>Register at OpenRouter</li> <li>Get an API Key</li> <li>Upload the API key in a file called <code>.env</code> at the root of the project. A sample <code>.env</code> file is given as <code>sample.env</code>, you can upload your API key in this file and rename it to <code>.env</code>.</li> </ol>"},{"location":"getting-started/installation/#installation","title":"Installation","text":"<p>Now that you have installed the dependencies, you can follow these steps to install Simone locally:</p> <ul> <li>Clone the repository:</li> </ul> <pre><code>git clone https://github.com/rajtilakjee/simone.git\n</code></pre> <ul> <li>Navigate to the project directory:</li> </ul> <pre><code>cd simone\n</code></pre> <ul> <li>Install requirements:</li> </ul> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#usage","title":"Usage","text":"<p>Post installation, this is how to run Simone:</p> <ul> <li>Run the script:</li> </ul> <pre><code>python main.py --url \"https://www.youtube.com/watch?v=1b2qPTmuLhg\" --path \"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n</code></pre>"},{"location":"script-info/roadmap/","title":"Roadmap","text":"<ol> <li>Make it available across platforms</li> <li>Availability of multiple LLMs</li> <li>Add unit tests</li> </ol>"}]}